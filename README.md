# sign_language_recognition using yolov7

ğŸ“Œ Project Overview:

Sign Language Recognition is an important assistive technology that helps bridge the communication gap between hearing-impaired individuals and the rest of society.
This project implements a real-time sign language recognition system using YOLOv7, a high-performance object detection model.
The system detects hand gestures from live video input and classifies them into predefined sign labels with fast and accurate real-time performance.

ğŸ¯ Objectives

â€¢ Detect hand gestures in real time using a webcam
â€¢ Train a deep learning model on a custom sign language dataset
â€¢ Achieve high accuracy with low inference latency
â€¢ Build a clean, modular, and extensible recognition pipeline

ğŸš€ Features

â€¢ Real-time webcam-based detection
â€¢ YOLOv7-powered object detection
â€¢ Custom dataset training support
â€¢ Clean and GitHub-friendly project structure
â€¢ Google Colab compatible training setup

ğŸ› ï¸ Tech Stack

â€¢ Programming Language: Python
â€¢ Deep Learning Framework: PyTorch
â€¢ Model: YOLOv7
â€¢ Computer Vision: OpenCV
â€¢ Training Environment: Google Colab / Local Machine
â€¢ Version Control: Git & GitHub

ğŸ“‚ Project Structure

sign-language-recognition/

â”‚

â”œâ”€â”€ README.md

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ .gitignore
â”‚

â”œâ”€â”€ data/
â”‚   â””â”€â”€ custom.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ detect_realtime.py
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ training_colab.ipynb
    
ğŸ“Š Dataset Details

â€¢ Custom sign language gesture dataset
â€¢ Images annotated in YOLO format
â€¢ Dataset split into training and validation sets

Dataset Configuration (data/custom.yaml)
(code)
train: data/images/train
val: data/images/val

nc: 1
names: ['sign']
âš ï¸ Dataset images and labels are not included in this repository due to size constraints.

âš™ï¸ Setup & Installation
1ï¸âƒ£ Clone YOLOv7 Repository
(Code)
git clone https://github.com/WongKinYiu/yolov7
2ï¸âƒ£ Install Dependencies
(Code)
pip install -r requirements.txt
3ï¸âƒ£ Download Pretrained Weights
Download yolov7.pt from the official YOLOv7 releases and place it in the project root or YOLOv7 directory.

ğŸ‹ï¸ Model Training
Run the training script:
(Code)python scripts/train_model.py
Trained model weights will be saved automatically in:
(Code)runs/train/exp/weights/

ğŸ¥ Real-Time Detection
To start live sign language recognition using a webcam:
(code)python scripts/detect_realtime.py

ğŸ“ˆ Results
â€¢ Accurate gesture detection on trained sign classes
â€¢ Smooth real-time inference
â€¢ Efficient performance using YOLOv7 architecture
(Performance depends on dataset quality and hardware configuration)
  
ğŸ§© Applications
â€¢ Assistive communication systems
â€¢ Educational tools for hearing-impaired learners
â€¢ Humanâ€“computer interaction
â€¢ Gesture-based control systems

ğŸ”® Future Enhancements
â€¢ Sentence-level sign language recognition
â€¢ Gesture-to-speech conversion
â€¢ Mobile or web-based deployment
â€¢ Support for multiple sign languages

âš ï¸ Important Note
â€¢ This project uses the official YOLOv7 implementation.
â€¢ The primary contributions of this project include:
â€¢ Dataset preparation and annotation
â€¢ Model training and fine-tuning
â€¢ Real-time inference pipeline
â€¢ Project integration and documentation

ğŸ‘¨â€ğŸ’» Team Members
â€¢ Dinesh Kumar M
â€¢ Dileep Adhithyan K
â€¢ Aathavan S K

ğŸ“œ License
This project is intended for academic and educational purposes only.

â­ Acknowledgements
â€¢ YOLOv7 by WongKinYiu
â€¢ PyTorch Community
â€¢ OpenCV Contributors



